{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import seaborn as sn\n",
    "import statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import chi2, SelectKBest, GenericUnivariateSelect\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE, f_classif\n",
    "from collections import Counter\n",
    "import xgboost\n",
    "# xgboost for feature importance on a regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "import pandas as pd \n",
    "import os \n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_name):\n",
    "    filepath = os.path.join('AML_2_dane', f'{dataset_name}_')\n",
    "    X = np.genfromtxt(filepath + 'train.data')\n",
    "    Y = np.genfromtxt(filepath + 'train.labels')\n",
    "    Y = (Y + 1)/2\n",
    "\n",
    "\n",
    "    return X, Y\n",
    "#X, Y = read_dataset('digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_univariate(X_train,y_train,args):\n",
    "  #perform univariate feature selection with a configurable strategy \n",
    "  #with hyper-parameter search estimator\n",
    "  fi, _ = chi2(X_train, y_train)\n",
    "  return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_boruta(X_train,y_train,classif_args, boruta_args):\n",
    "\n",
    "    rf = RandomForestClassifier(**classif_args)\n",
    "\n",
    "    # define Boruta feature selection method\n",
    "    feat_selector = BorutaPy(rf, **boruta_args)\n",
    "    feat_selector.fit(X_train, y_train)\n",
    "\n",
    "    # check selected features - first 5 features are selected\n",
    "    return -feat_selector.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_MCFS(X_train,y_train, mcfs_args):\n",
    "    fs = return_MCFS(X_train,y_train, **{arg: value for arg, value in mcfs_args.items() if arg !='topk'})\n",
    "    #top_indices =  np.argpartition(fs, -mcfs_args['topk'])[-mcfs_args['topk']:]\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_random_forest(X_train,y_train, rf_args):\n",
    "    rfc = RandomForestClassifier(**{arg: value for arg, value in rf_args.items() if arg !='topk'})\n",
    "    rfc.fit(X_train, y_train)\n",
    "    #top_indices =  np.argpartition(rfc.feature_importances_, -rf_args['topk'])[-rf_args['topk']:]\n",
    "    return rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_k_indices(feature_importance, topk): \n",
    "    return np.argpartition(feature_importance, -topk)[-topk:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_fs(chi2_fi, boruta_fi, MCFS_fi, random_forest_fi, topk):\n",
    "    chi2_indices = select_top_k_indices(chi2_fi, topk)\n",
    "    boruta_indices = select_top_k_indices(boruta_fi, topk)\n",
    "    MCFS_indices = select_top_k_indices(MCFS_fi, topk)\n",
    "    random_forest_indices = select_top_k_indices(random_forest_fi, topk)\n",
    "    all_indices = np.r_[chi2_indices, boruta_indices, MCFS_indices, random_forest_indices]\n",
    "    counter = Counter(all_indices)\n",
    "    indices = [idx for idx, value in counter.items() if value > 1]\n",
    "    return np.array(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from MCFS import return_MCFS\n",
    "\n",
    "def return_fi(X_train,y_train, method, method_args): \n",
    "    if method == 'chi2': \n",
    "        return fs_univariate(X_train,y_train, method_args)\n",
    "    elif method == 'boruta':    \n",
    "        return fs_boruta(X_train,y_train, method_args['classif_args'], method_args['boruta_args'])\n",
    "    elif method == 'MCFS': \n",
    "        return fs_MCFS(X_train,y_train, method_args)\n",
    "    elif method == 'RandomForest': \n",
    "        return fs_random_forest(X_train,y_train, method_args)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_aml_score(balanced_accuracy, m_features_chosen, dataset='artificial'):\n",
    "    if dataset == 'artificial':\n",
    "        return balanced_accuracy - max(0, 0.01*(0.2*m_features_chosen-1))\n",
    "    elif dataset == 'digits': \n",
    "        return balanced_accuracy - max(0, 0.01*(0.005*m_features_chosen-0.25))\n",
    "    else: \n",
    "        raise ValueError(f\"wrong dataset: {dataset}\")\n",
    "assert return_aml_score(0.9, 5) == 0.9\n",
    "assert return_aml_score(0.9, 20) == 0.87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metrics(model, X_test, y_test, dataset): \n",
    "    yhat = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, yhat)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, yhat)\n",
    "    aml_score = return_aml_score(balanced_accuracy, X_test.shape[1], dataset)\n",
    "    return accuracy, balanced_accuracy, aml_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_ccp_alpha(X, Y): \n",
    "    print('return_best_ccp_alpha')\n",
    "    alphas = np.linspace(0, 1.0, 15)\n",
    "    parameters = {'ccp_alpha': alphas}\n",
    "    model = RandomForestClassifier()\n",
    "    gscv = GridSearchCV(model, parameters, cv=5)\n",
    "    gscv.fit(X, Y)\n",
    "    return gscv.best_params_['ccp_alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_gen(X, Y): \n",
    "    kfolds = KFold(n_splits=5, shuffle=True)\n",
    "    for train_idx, test_idx in kfolds.split(X, Y):\n",
    "        x_train = X[train_idx]\n",
    "        x_test = X[test_idx]\n",
    "\n",
    "        y_train = Y[train_idx]\n",
    "        y_test = Y[test_idx]\n",
    "        yield x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'xgboost': lambda : XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    'random_forest': lambda ccp_alpha: RandomForestClassifier(ccp_alpha=ccp_alpha)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "1\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "2\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "3\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "4\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "return_best_ccp_alpha\n",
      "0.0\n",
      "0\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "1\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "2\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "3\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n",
      "4\n",
      "0/6\n",
      "1/6\n",
      "2/6\n",
      "3/6\n",
      "4/6\n",
      "5/6\n"
     ]
    }
   ],
   "source": [
    "from frozendict import frozendict\n",
    "best_ccp_alphas = {'artificial': 0.0}\n",
    "def grid_search(dataset, config, percentiles=(0.1,)): \n",
    "    X, Y  = read_dataset(dataset)\n",
    "    if dataset in best_ccp_alphas:\n",
    "        best_ccp_alpha = best_ccp_alphas.get(dataset)\n",
    "    else: \n",
    "        best_ccp_alpha = return_best_ccp_alpha(X, Y)\n",
    "    print(best_ccp_alpha)\n",
    "    metrics = {model_name: {method_name: {percentile: {\"accuracies\": [], \"balanced_accuracies\": [], \"aml_scores\": []} for percentile in percentiles} for method_name in ['chi2', 'boruta', 'MCFS', 'RandomForest']}   for model_name in models}\n",
    "    results = []\n",
    "    for idx_fold, (x_train, x_test, y_train, y_test) in enumerate(cv_gen(X, Y)):\n",
    "        print(idx_fold)\n",
    "        x_train, x_test = scale(x_train, x_test)\n",
    "        for cfg_idx, args in enumerate(config['config']):\n",
    "            print(f'{cfg_idx}/{len(config[\"config\"])}', end='\\r')\n",
    "            args['results'] = []\n",
    "            if args['method'] == 'MCFS' and args['method_args']['m'] > X.shape[1]: \n",
    "                continue\n",
    "            fi = return_fi(x_train, y_train, args['method'], args['method_args'])\n",
    "            for percentile in percentiles: \n",
    "                print(int(X.shape[1]*percentile/100))\n",
    "                indices = select_top_k_indices(fi, int(X.shape[1]*percentile/100))\n",
    "                x_train_cut = x_train[:, indices]\n",
    "                x_test_cut = x_test[:, indices]\n",
    "                for model_name, model in models.items(): \n",
    "                    if model_name == 'xgboost': \n",
    "                        model = model()\n",
    "                    else: \n",
    "                        model = model(best_ccp_alpha)\n",
    "                    model.fit(x_train_cut, y_train)\n",
    "                    accuracy, balanced_accuracy, aml_score = return_metrics(model, x_test_cut, y_test, dataset=dataset)\n",
    "                    args['results'].append({\"percentile\": percentile, \n",
    "                                        \"model_name\": model_name,\n",
    "                                        \"accuracy\": accuracy,\n",
    "                                        \"balanced_accuracy\": balanced_accuracy,\n",
    "                                        \"aml_score\": aml_score\n",
    "                                        })\n",
    "            results.append(args)\n",
    "            with open(f'results_{dataset}_loxxxxtile.json', 'w') as file: \n",
    "                json.dump({\"results\": results}, file)\n",
    "            print()\n",
    "\n",
    "with open('fs_config.json', 'rb') as file: \n",
    "    config = json.load(file)\n",
    "\n",
    "\n",
    "config['config'] = [conf for idx, conf in enumerate(config['config']) if conf['method'] != 'MCFS' or (conf['method'] == 'MCFS' and conf['method_args']['u'] == 1 and conf['method_args']['v'] == 1 and conf['method_args']['m'] == 5)]\n",
    "grid_search('artificial', config)\n",
    "grid_search('digits', config)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3e120fe12df1b828d3ef4b0e8795aa8da37806a8e26ad72b106d26bdc35510f8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
